{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r05XFySmdBjD",
        "outputId": "2c93f677-b828-475b-bb67-2a532387773b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CompletedProcess(args=['kaggle', 'datasets', 'download', '-d', 'psparks/instacart-market-basket-analysis', '--unzip'], returncode=0)"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ---------------------------------------------------------------------------\n",
        "# 0ï¸âƒ£  Setup â€“ install / download once per runtime\n",
        "# ---------------------------------------------------------------------------\n",
        "import os, json, subprocess, sys\n",
        "os.makedirs(os.path.expanduser(\"~/.kaggle\"), exist_ok=True)\n",
        "with open(os.path.expanduser(\"~/.kaggle/kaggle.json\"), \"w\") as f:\n",
        "    json.dump({\"username\": \"dashanrichards\", \"key\": \"5f7a6f0b215f4b54682829ccf7c1fab4\"}, f)\n",
        "os.chmod(os.path.expanduser(\"~/.kaggle/kaggle.json\"), 0o600)\n",
        "\n",
        "# â–¸ Download + unzip dataset\n",
        "subprocess.run([\"kaggle\", \"datasets\", \"download\",\n",
        "                \"-d\", \"psparks/instacart-market-basket-analysis\", \"--unzip\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "71S_oUJKdQaE"
      },
      "outputs": [],
      "source": [
        "# ---------------------------------------------------------------------------\n",
        "# 1ï¸âƒ£  Imports\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Tuple, List, Dict\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HRtq7G-kd0kH"
      },
      "outputs": [],
      "source": [
        "# ---------------------------------------------------------------------------\n",
        "# 2ï¸âƒ£  Modular pipeline functions\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "# ----- 2.1 Load raw data ----------------------------------------------------\n",
        "def load_instacart_data(data_dir: Path = Path(\".\")) -> Tuple[pd.DataFrame, ...]:\n",
        "    \"\"\"Load Instacart CSVs from `data_dir`.\"\"\"\n",
        "    orders       = pd.read_csv(data_dir / \"orders.csv\")\n",
        "    order_prior  = pd.read_csv(data_dir / \"order_products__prior.csv\")\n",
        "    products     = pd.read_csv(data_dir / \"products.csv\")\n",
        "    aisles       = pd.read_csv(data_dir / \"aisles.csv\")\n",
        "    departments  = pd.read_csv(data_dir / \"departments.csv\")\n",
        "    return orders, order_prior, products, aisles, departments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Q9GQD0r_d_7f"
      },
      "outputs": [],
      "source": [
        "# ----- 2.2 Build timeline & daily demand ------------------------------------\n",
        "def generate_order_timeline(\n",
        "    orders: pd.DataFrame,\n",
        "    order_prior: pd.DataFrame,\n",
        "    epoch: str = \"2023-01-01\"\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Merge order header + line items and add pseudo-dates.\"\"\"\n",
        "    orders = orders[orders.eval_set == \"prior\"]\n",
        "    merged = order_prior.merge(\n",
        "        orders[[\"order_id\", \"user_id\", \"order_number\",\n",
        "                \"order_dow\", \"order_hour_of_day\", \"days_since_prior_order\"]],\n",
        "        on=\"order_id\", how=\"left\"\n",
        "    )\n",
        "    merged[\"days_since_prior_order\"] = merged[\"days_since_prior_order\"].fillna(0)\n",
        "    merged[\"order_date\"] = (\n",
        "        pd.to_timedelta(\n",
        "            merged.groupby(\"user_id\")[\"days_since_prior_order\"].cumsum(), unit=\"D\"\n",
        "        ) + pd.to_datetime(epoch)\n",
        "    )\n",
        "    # Optional time features\n",
        "    merged[\"dow\"]        = merged[\"order_date\"].dt.dayofweek\n",
        "    merged[\"is_weekend\"] = merged[\"dow\"].isin([5, 6]).astype(int)\n",
        "    return merged\n",
        "\n",
        "\n",
        "def calculate_daily_demand(timeline_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Aggregate to daily SKU demand.\"\"\"\n",
        "    return (\n",
        "        timeline_df.groupby([\"order_date\", \"product_id\"])\n",
        "        .size()\n",
        "        .reset_index(name=\"demand\")\n",
        "        .rename(columns={\"order_date\": \"date\"})\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4H4ZqhFveEYm"
      },
      "outputs": [],
      "source": [
        "# ----- 2.3  Inventory config -------------------------------------------------\n",
        "def setup_inventory(\n",
        "    product_ids: np.ndarray,\n",
        "    start_date: pd.Timestamp,\n",
        "    end_date: pd.Timestamp,\n",
        "    products_meta: pd.DataFrame | None = None,\n",
        ") -> Tuple[pd.DataFrame, pd.DatetimeIndex]:\n",
        "    \"\"\"Create random inventory policies (editable later by agents).\"\"\"\n",
        "    inv_cfg = pd.DataFrame({\n",
        "        \"product_id\": product_ids,\n",
        "        \"initial_inventory\"    : np.random.randint(500, 1000, size=len(product_ids)),\n",
        "        \"restock_every_n_days\" : np.random.choice([7, 14],  size=len(product_ids)),\n",
        "        \"restock_amount\"       : np.random.randint(300, 600,  size=len(product_ids)),\n",
        "    }).set_index(\"product_id\")\n",
        "\n",
        "    if products_meta is not None:\n",
        "        products_meta = products_meta.reset_index()\n",
        "        inv_cfg = (\n",
        "            inv_cfg.merge(products_meta, on=\"product_id\", how=\"left\")\n",
        "                   .set_index(\"product_id\")\n",
        "        )\n",
        "    sim_days = pd.date_range(start=start_date, end=end_date, freq=\"D\")\n",
        "    return inv_cfg, sim_days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9mD8bbxWeJY9"
      },
      "outputs": [],
      "source": [
        "# ----- 2.4  Core simulation --------------------------------------------------\n",
        "def simulate_stockouts(\n",
        "    daily_demand: pd.DataFrame,\n",
        "    inv_cfg: pd.DataFrame,\n",
        "    sim_days: pd.DatetimeIndex,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Loop-based simulation (easy to read & agent-friendly).\n",
        "    Vectorization is possible later if scale becomes an issue.\n",
        "    \"\"\"\n",
        "    # State dict for every SKU\n",
        "    state: Dict[int, Dict[str, any]] = {\n",
        "        pid: {\"inv\": inv_cfg.loc[pid, \"initial_inventory\"],\n",
        "              \"last_restock\": sim_days[0]}\n",
        "        for pid in inv_cfg.index\n",
        "    }\n",
        "\n",
        "    records: List[Dict] = []\n",
        "\n",
        "    demand_grouped = {d: df for d, df in daily_demand.groupby(\"date\", sort=False)}\n",
        "\n",
        "    for day in sim_days:\n",
        "        daily_df = demand_grouped.get(day, None)\n",
        "        if daily_df is None:\n",
        "            continue  # no demand that day\n",
        "\n",
        "        for _, row in daily_df.iterrows():\n",
        "            pid, demand = int(row.product_id), int(row.demand)\n",
        "            cfg   = inv_cfg.loc[pid]\n",
        "            s     = state[pid]\n",
        "\n",
        "            # Restock if due\n",
        "            if (day - s[\"last_restock\"]).days >= cfg.restock_every_n_days:\n",
        "                s[\"inv\"]         += cfg.restock_amount\n",
        "                s[\"last_restock\"] = day\n",
        "\n",
        "            fulfilled = min(demand, s[\"inv\"])\n",
        "            stockout  = int(fulfilled < demand)\n",
        "            s[\"inv\"] -= fulfilled\n",
        "\n",
        "            records.append({\n",
        "                \"date\"               : day,\n",
        "                \"product_id\"         : pid,\n",
        "                \"demand\"             : demand,\n",
        "                \"fulfilled\"          : fulfilled,\n",
        "                \"stockout\"           : stockout,\n",
        "                \"remaining_inventory\": s[\"inv\"],\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(records)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebdF7PO_eNi2",
        "outputId": "6332582b-14d8-4c03-d144-bcfb982cf2e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Loading data â€¦\n",
            "ğŸ“… Building timeline â€¦\n",
            "ğŸ—ï¸  Preparing inventory config â€¦\n",
            "ğŸšš Simulating inventory flow â€¦\n"
          ]
        }
      ],
      "source": [
        "# ---------------------------------------------------------------------------\n",
        "# 3ï¸âƒ£  Driver / orchestrator (can be run as `python stockout_sim.py`)\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"ğŸ”„ Loading data â€¦\")\n",
        "    ORDERS, PRIOR, PRODUCTS, AISLES, DEPTS = load_instacart_data()\n",
        "\n",
        "    print(\"ğŸ“… Building timeline â€¦\")\n",
        "    order_timeline      = generate_order_timeline(ORDERS, PRIOR)\n",
        "    daily_demand_df     = calculate_daily_demand(order_timeline)\n",
        "\n",
        "    print(\"ğŸ—ï¸  Preparing inventory config â€¦\")\n",
        "    product_meta = (\n",
        "        PRODUCTS.merge(AISLES, on=\"aisle_id\", how=\"left\")\n",
        "                .merge(DEPTS, on=\"department_id\", how=\"left\")\n",
        "                .set_index(\"product_id\")\n",
        "    )\n",
        "\n",
        "    INV_CFG, SIM_DAYS = setup_inventory(\n",
        "        daily_demand_df.product_id.unique(),\n",
        "        daily_demand_df.date.min(),\n",
        "        daily_demand_df.date.max(),\n",
        "        products_meta=product_meta,\n",
        "    )\n",
        "\n",
        "    print(\"ğŸšš Simulating inventory flow â€¦\")\n",
        "    stockout_df = simulate_stockouts(daily_demand_df, INV_CFG, SIM_DAYS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlxbUVQ1eSmi",
        "outputId": "08fa776c-9052-409c-c9e2-85f9b8e6ba71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âœ… Simulation complete.\n",
            "        date  product_id  demand  fulfilled  stockout  remaining_inventory\n",
            "0 2023-01-01           1      15         15         0                  519\n",
            "1 2023-01-01           3       2          2         0                  575\n",
            "2 2023-01-01           4       7          7         0                  868\n",
            "3 2023-01-01           7       1          1         0                  654\n",
            "4 2023-01-01           8       2          2         0                  706\n",
            "\n",
            "ğŸ”  Overall stockout rate: 0.06%\n"
          ]
        }
      ],
      "source": [
        "    # -----------------------------------------------------------------------\n",
        "    # 4ï¸âƒ£  Output / hand-off for agents, dashboards, ML, etc.\n",
        "    # -----------------------------------------------------------------------\n",
        "\n",
        "    print(\"\\nâœ… Simulation complete.\")\n",
        "    print(stockout_df.head())\n",
        "\n",
        "    # Example KPI\n",
        "    kpi = stockout_df.stockout.mean()\n",
        "    print(f\"\\nğŸ”  Overall stockout rate: {kpi:.2%}\")\n",
        "\n",
        "    # Save for later steps (forecasting, LLM prompts, dashboards)\n",
        "    stockout_df.to_csv(\"stockout_results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AT6mphYKbZY6",
        "outputId": "28003c31-3fab-4056-8f23-8b4bde20a8dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       product_id  total_days  stockout_days  avg_remaining_inv  total_demand  \\\n",
            "24848       24852        9534           2057       52503.506503        472565   \n",
            "26204       26209        8172            887       37603.587004        140627   \n",
            "47755       47766        8254            816       53490.816331        176815   \n",
            "27839       27845        7925            781       37372.263470        137905   \n",
            "21133       21137        9307            874       89304.953691        264683   \n",
            "13172       13176        9325            796      160184.040107        379450   \n",
            "47615       47626        8157            662       56272.565649        152657   \n",
            "21899       21903        8875            554      125959.421859        241921   \n",
            "16793       16797        7887            396       91972.548878        142951   \n",
            "4917         4920        7576            366       43478.517423         82689   \n",
            "\n",
            "       stockout_rate  \n",
            "24848       0.215754  \n",
            "26204       0.108541  \n",
            "47755       0.098861  \n",
            "27839       0.098549  \n",
            "21133       0.093908  \n",
            "13172       0.085362  \n",
            "47615       0.081157  \n",
            "21899       0.062423  \n",
            "16793       0.050209  \n",
            "4917        0.048310  \n"
          ]
        }
      ],
      "source": [
        "# Top SKUs by stockout frequency\n",
        "sku_stockout_summary = stockout_df.groupby('product_id').agg(\n",
        "    total_days=('date', 'count'),\n",
        "    stockout_days=('stockout', 'sum'),\n",
        "    avg_remaining_inv=('remaining_inventory', 'mean'),\n",
        "    total_demand=('demand', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "sku_stockout_summary['stockout_rate'] = (\n",
        "    sku_stockout_summary['stockout_days'] / sku_stockout_summary['total_days']\n",
        ")\n",
        "\n",
        "# Sort by worst stockout rate\n",
        "top_stockout_skus = sku_stockout_summary.sort_values('stockout_rate', ascending=False).head(10)\n",
        "print(top_stockout_skus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUCoa-_dNkPg",
        "outputId": "8be23cd2-73be-4fc0-863d-bdf7af03c842"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting shap\n",
            "  Downloading shap-0.48.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from shap) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from shap) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.11/dist-packages (from shap) (25.0)\n",
            "Collecting slicer==0.0.8 (from shap)\n",
            "  Downloading slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from shap) (0.61.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from shap) (4.14.1)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->shap) (0.44.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n",
            "Downloading shap-0.48.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading slicer-0.0.8-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.48.0 slicer-0.0.8\n",
            "Collecting lightgbm\n",
            "  Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.15.3)\n",
            "Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightgbm\n",
            "Successfully installed lightgbm-4.6.0\n",
            "Collecting xgboost\n",
            "  Downloading xgboost-3.0.2-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n",
            "Collecting nvidia-nccl-cu12 (from xgboost)\n",
            "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.3)\n",
            "Downloading xgboost-3.0.2-py3-none-manylinux_2_28_x86_64.whl (253.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m253.9/253.9 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost\n",
            "Successfully installed nvidia-nccl-cu12-2.27.5 xgboost-3.0.2\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting graphviz (from catboost)\n",
            "  Downloading graphviz-0.21-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphviz-0.21-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: graphviz, catboost\n",
            "Successfully installed catboost-1.2.8 graphviz-0.21\n"
          ]
        }
      ],
      "source": [
        "!pip install shap\n",
        "!pip install lightgbm\n",
        "!pip install xgboost\n",
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KtHEX9x_cA3M"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "import shap\n",
        "import time\n",
        "import joblib\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "g8vRZK2u2eNf"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# --- Load preprocessed dataset ---\n",
        "stockout_df = pd.read_csv(\"stockout_results.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1B1er_zS2eBQ"
      },
      "outputs": [],
      "source": [
        "# --- Feature Engineering ---\n",
        "stockout_df['day_of_week'] = pd.to_datetime(stockout_df['date']).dt.dayofweek\n",
        "stockout_df['demand_lag_1'] = stockout_df.groupby('product_id')['demand'].shift(1)\n",
        "stockout_df['inventory_lag_1'] = stockout_df.groupby('product_id')['remaining_inventory'].shift(1)\n",
        "stockout_df['target'] = stockout_df.groupby('product_id')['stockout'].shift(-1)\n",
        "\n",
        "model_df = stockout_df.dropna(subset=['demand_lag_1', 'inventory_lag_1', 'target'])\n",
        "\n",
        "X = model_df[['day_of_week', 'demand', 'demand_lag_1', 'inventory_lag_1']]\n",
        "y = model_df['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- Define Models ---\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=500),\n",
        "    \"Random Forest\"      : RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"LightGBM\"           : LGBMClassifier(verbose=-1),\n",
        "    \"XGBoost\"            : XGBClassifier(use_label_encoder=False, eval_metric='logloss', verbosity=0),\n",
        "    \"CatBoost\"           : CatBoostClassifier(verbose=0)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41KjuMik2lS2",
        "outputId": "bc53912d-6aac-43a6-bda1-b4bddf54daa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model                  |    F1 | Precision |  Recall | Train Time (s)\n",
            "----------------------------------------------------------------------\n",
            "Logistic Regression    | 0.653 |     0.811 |   0.546 |         13.417\n",
            "Random Forest          | 0.911 |     0.941 |   0.883 |       1112.649\n",
            "LightGBM               | 0.341 |     0.514 |   0.255 |          8.452\n",
            "XGBoost                | 0.504 |     0.489 |   0.521 |          7.610\n",
            "CatBoost               | 0.595 |     0.706 |   0.514 |        168.502\n"
          ]
        }
      ],
      "source": [
        "# --- Benchmark Models ---\n",
        "results = []\n",
        "trained_models = {}\n",
        "\n",
        "print(f\"{'Model':<22} | {'F1':>5} | {'Precision':>9} | {'Recall':>7} | {'Train Time (s)':>14}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for name, model in models.items():\n",
        "    start = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    end = time.time()\n",
        "\n",
        "    preds = model.predict(X_test)\n",
        "    f1 = f1_score(y_test, preds)\n",
        "    prec = precision_score(y_test, preds)\n",
        "    rec = recall_score(y_test, preds)\n",
        "    duration = end - start\n",
        "\n",
        "    results.append({\n",
        "        \"Model\": name,\n",
        "        \"F1 Score\": round(f1, 3),\n",
        "        \"Precision\": round(prec, 3),\n",
        "        \"Recall\": round(rec, 3),\n",
        "        \"Train Time (s)\": round(duration, 3)\n",
        "    })\n",
        "\n",
        "    trained_models[name] = model\n",
        "    print(f\"{name:<22} | {f1:>5.3f} | {prec:>9.3f} | {rec:>7.3f} | {duration:>14.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pFoj3O542pI2"
      },
      "outputs": [],
      "source": [
        "# --- Results DataFrame ---\n",
        "results_df = pd.DataFrame(results).sort_values(by='F1 Score', ascending=False).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moua2WV22sAr",
        "outputId": "25257de7-2ffc-4be5-bd89-2ecc568e139a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ” Best Model: Random Forest\n"
          ]
        }
      ],
      "source": [
        "# --- SHAP Explainability for Best Model ---\n",
        "best_model_name = results_df.iloc[0][\"Model\"]\n",
        "best_model = trained_models[best_model_name]\n",
        "\n",
        "print(f\"\\nğŸ” Best Model: {best_model_name}\")\n",
        "\n",
        "X_train_np = X_train.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTUYV74S2o7q",
        "outputId": "d0af7990-26f6-421b-a84a-44f6c12611f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Model saved to: best_model_random_forest.pkl\n"
          ]
        }
      ],
      "source": [
        "# --- Save the Best Model ---\n",
        "joblib.dump(best_model, f\"best_model_{best_mvodel_name.replace(' ', '_').lower()}.pkl\")\n",
        "print(f\"âœ… Model saved to: best_model_{best_model_name.replace(' ', '_').lower()}.pkl\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V6E1",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
